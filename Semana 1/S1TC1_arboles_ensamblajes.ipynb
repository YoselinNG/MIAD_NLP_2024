{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller: Construcción e implementación de árboles de decisión y métodos de ensamblaje\n",
    "\n",
    "En este taller podrá poner en práctica los sus conocimientos sobre construcción e implementación de árboles de decisión y métodos de ensamblajes. El taller está constituido por 9 puntos, 5 relacionados con árboles de decisión (parte A) y 4 con métodos de ensamblaje (parte B)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte A - Árboles de decisión\n",
    "\n",
    "En esta parte del taller se usará el conjunto de datos de Capital Bikeshare de Kaggle, donde cada observación representa el alquiler de bicicletas durante una hora y día determinado. Para más detalles puede visitar los siguientes enlaces: [datos](https://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip), [dicccionario de datos](https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset#)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos prestamo de bicicletas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de la información de archivo .csv\n",
    "bikes = pd.read_csv('https://raw.githubusercontent.com/davidzarruk/MIAD_ML_NLP_2023/main/datasets/bikeshare.csv', index_col='datetime', parse_dates=True)\n",
    "\n",
    "# Renombrar variable \"count\" a \"total\"\n",
    "bikes.rename(columns={'count':'total'}, inplace=True)\n",
    "\n",
    "# Crear la hora como una variable \n",
    "bikes['hour'] = bikes.index.hour\n",
    "\n",
    "# Visualización de los datos\n",
    "bikes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 1 - Análisis descriptivo\n",
    "\n",
    "Ejecute las celdas 1.1 y 1.2. A partir de los resultados realice un análisis descriptivo sobre las variables \"season\" y \"hour\", escriba sus inferencias sobre los datos. Para complementar su análisis puede usar métricas como máximo, mínimo, percentiles entre otros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 1.1\n",
    "bikes.groupby('season').total.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frecuencia de cada estación\n",
    "station_counts = bikes['season'].value_counts()\n",
    "print(\"la frecuencia de cada estación es: \"+ str (station_counts))\n",
    "import matplotlib.pyplot as plt\n",
    "# Crear el histograma\n",
    "plt.bar(station_counts.index, station_counts.values)\n",
    "\n",
    "# Agregar etiquetas y título\n",
    "plt.xlabel('Estación')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Frecuencia de Estaciones del Año')\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Crear el diagrama de cajas\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='season', y='total', data=bikes)\n",
    "\n",
    "# Agregar etiquetas y título\n",
    "plt.xlabel('Estación del Año')\n",
    "plt.ylabel('Cantidad Total de Bicicletas Alquiladas')\n",
    "plt.title('Diagrama de Caja de Alquiler de Bicicletas por Estación del Año')\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis descriptivo variable \"season\":\n",
    "A partir del diccionario sabemos que la variable contiene 4 categorías (1:winter, 2:spring, 3:summer, 4:fall), el analisis preliminar permite saber que en verano se tiene el mayor promedio de alquiler de bicicletas, mientras que en invierno este promedio es el mas bajo, siendo un poco menos de la mitad del promedio de alquileres de verano. \n",
    "El análisis de la frecuencia de la variable season sugiere que los datos tienen una distribucion relativamente uniforme o equilibrada entre estaciones.\n",
    "El análisis de cajas y bigotes para la cantidad de bicicletas alquiladas por estación, muestra la presencia de datos atípicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Celda 1.2\n",
    "bikes.groupby('hour').total.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el promedio de la variable 'total' agrupado por la variable 'hour'\n",
    "hourly_mean = bikes.groupby('hour')['total'].mean()\n",
    "\n",
    "# Imprimir estadísticas descriptivas\n",
    "print(\"Estadísticas Descriptivas de la Cantidad Total de Bicicletas Alquiladas por Hora:\")\n",
    "print(hourly_mean.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diagrama de caja para Hour\n",
    "# Crear el diagrama de caja\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='hour', y='total', data=bikes)\n",
    "\n",
    "# Agregar etiquetas y título\n",
    "plt.xlabel('Hora del Día')\n",
    "plt.ylabel('Cantidad Total de Bicicletas Alquiladas')\n",
    "plt.title('Diagrama de Caja de Alquiler de Bicicletas por Hora del Día')\n",
    "\n",
    "# Rotar etiquetas del eje x para mayor legibilidad\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis descriptivo de \"hour\"\n",
    "La variable hour contiene informacion de las horas de alquiler de las bicicletas, se puede ver que la hora con mayor cantidad de bicicletas alquiladas es aproximadamente 469 bicicletas, esto sucede a las 17 horas, la minima cantidad de bicicletas alquiladas es aproximadamente 6 y ocurre a las 4 de la mañana, el promedio de bicicletas alquiladas por hora es 191 con una desviación estándar de 133, lo que implica que los datos son muy variados en lo que respecta al total de bicicletas alquiladas por hora. El 75% de los valores del total de bicicletas alquiladas por hora está por debajo de 257 y el 25% por debajo de  71 bicicletas alquiladas por hora. Por último se puede ver que el 50% de las horas tienen un total de bicicletas alquiladas igual o menor que  212.\n",
    "Finalmente podemos observar que algunas horas, especialmente las de menor cantidad de bicicletas alquiladas presentan datos atípicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 2 - Análisis de gráficos\n",
    "\n",
    "Primero ejecute la celda 2.1 y asegúrese de comprender el código y el resultado. Luego, en cada una de celdas 2.2 y 2.3 escriba un código que genere una gráfica del número de bicicletas rentadas promedio para cada valor de la variable \"hour\" (hora) cuando la variable \"season\" es igual a 1 (invierno) e igual a 3 (verano), respectivamente. Analice y escriba sus hallazgos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 2.1 - rentas promedio para cada valor de la variable \"hour\"\n",
    "bikes.groupby('hour').total.mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 2.2 - \"season\"=1 escriba su código y hallazgos \n",
    "# renta de Bicicletas en Invierno\n",
    "# Se filtra el DataFrame para incluir solo las filas donde \"season\" sea igual a 1\n",
    "bikes_season_1 = bikes[bikes['season'] == 1]\n",
    "\n",
    "# Calcular la renta promedio para cada valor de la variable \"hour\" en los datos filtrados\n",
    "rentas_promedio_season_1 = bikes_season_1.groupby('hour')['total'].mean()\n",
    "\n",
    "# Graficar los resultados\n",
    "rentas_promedio_season_1.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 2.3 - \"season\"=3 escriba su código y hallazgos \n",
    "# Filtrar el DataFrame para incluir solo las filas donde \"season\" sea igual a 3\n",
    "bikes_season_2 = bikes[bikes['season'] == 3]\n",
    "\n",
    "# Calcular la renta promedio para cada valor de la variable \"hour\" en los datos filtrados\n",
    "rentas_promedio_season_2 = bikes_season_2.groupby('hour')['total'].mean()\n",
    "\n",
    "# Graficar los resultados\n",
    "rentas_promedio_season_2.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hallazgos del punto 2\n",
    "- En el gráfico de la celda 2.1 se puede observar cómo se distribuye el numero promedio de bicicletas rentadas por hora, podemos notar que este promedio es menor en las primeras horas del día y al final del día, con los picos entre las 5 y 10 am y en la tarde entre las 15 y las primeras horas de la noche, se puede observar la influencia del máximo encontrado en los datos analizados en el punto 1 a las 17 horas.\n",
    "- Gráfico de la celda 2.2 (Invierno) : en el invierno el comportamiento general de variabilidad de renta promedio de bicicletas gráficamente es semejante al 2.1, sin embargo los rango son mucho más bajos, disminuye notablemente en invierno el promedio de bicicletas rentadas. El pico de renta que se encontraba en la mañana en por encima de 300 en el gráfico de 2.1, en invierno se sitúa por debajo de 250, gual pasa con la cantidad de bicicletas rentadas en las horas de la tarde.\n",
    "- Gráfico 2.3 (Verano): En verano,se encuentran los mayores promedio de bicicletas rentadas por hora, con el pico mas alto en las horas de la tarde, el cual se encuentra por encima de 500, superando al encontrado en el gráfico del total (celda 2.1). Lo mismo ocurre con el pico de renta promedio situado entre las 5 y 10 am, el cual se encuentra por encima de los dos gráficos anteriores. Al igual que en los dos gráficos anteriores, los valores más bajos se encuentran entre las 0 y 5 horas y despues de las 20 horas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 3 - Regresión lineal\n",
    "En la celda 3 ajuste un modelo de regresión lineal a todo el conjunto de datos, utilizando \"total\" como variable de respuesta y \"season\" y \"hour\" como las únicas variables predictoras, teniendo en cuenta que la variable \"season\" es categórica. Luego, imprima los coeficientes e interprételos. ¿Cuáles son las limitaciones de la regresión lineal en este caso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 3\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Obtener las variables predictoras y la variable de respuesta\n",
    "X = bikes[['season', 'hour']]\n",
    "y = bikes['total']\n",
    "\n",
    "# Ajustar el modelo de regresión lineal\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Coeficientes del modelo\n",
    "coef_season = model.coef_[0]  # Coeficiente para 'season'\n",
    "coef_hour = model.coef_[1]    # Coeficiente para 'hour'\n",
    "intercepto = model.intercept_  # Término independiente\n",
    "\n",
    "print(\"Coeficientes del modelo:\")\n",
    "print(\"Coeficiente para 'season':\", coef_season)\n",
    "print(\"Coeficiente para 'hour':\", coef_hour)\n",
    "print(\"Intercepto:\", intercepto)\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Hacer predicciones con el modelo de regresión lineal\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Calcular el coeficiente de determinación (R^2)\n",
    "r2 = r2_score(y, predictions)\n",
    "print(\"R^2 Score:\", r2)\n",
    "\n",
    "# Calcular el error cuadrático medio (MSE)\n",
    "mse = mean_squared_error(y, predictions)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "mae = np.mean(np.abs(y, predictions))\n",
    "print(\"MAE:\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "#prueba para mirar la linealidad de la relación entre estaciones y promedio de renta de bicicletas\n",
    "# Dividir los datos en grupos según la estación del año\n",
    "winter_rentals = bikes[bikes['season'] == 1]['total']\n",
    "spring_rentals = bikes[bikes['season'] == 2]['total']\n",
    "summer_rentals = bikes[bikes['season'] == 3]['total']\n",
    "fall_rentals = bikes[bikes['season'] == 4]['total']\n",
    "\n",
    "# Realizar la prueba ANOVA si p es <0.05 indica diferencia significativa\n",
    "anova_results = f_oneway(winter_rentals, spring_rentals, summer_rentals, fall_rentals)\n",
    "\n",
    "# Imprimir el resultado\n",
    "print(\"Valor p de la prueba ANOVA:\", anova_results.pvalue)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calcular la cantidad promedio de bicicletas alquiladas para cada estación del año\n",
    "mean_rentals_by_season = bikes.groupby('season')['total'].mean()\n",
    "\n",
    "# Crear el gráfico de barras\n",
    "plt.bar(mean_rentals_by_season.index, mean_rentals_by_season)\n",
    "plt.xlabel('Estación del Año')\n",
    "plt.ylabel('Cantidad Promedio de Bicicletas Alquiladas')\n",
    "plt.title('Cantidad Promedio de Bicicletas Alquiladas por Estación del Año')\n",
    "plt.xticks([1, 2, 3, 4], ['Invierno', 'Primavera', 'Verano', 'Otoño'])\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretación resultados punto 3\n",
    "Para este caso puede interpretarse el coeficiente para \"Hour\" como que en promedio por cada hora adicional se aumente el numero de bicicletas rentadas en 10.5 unidades manteniendo constante la estación del año.\n",
    "Para el caso de la variable \"Season\", los resultados del modelo de regresión lineal indican que hay un aumento de 26.9 unidades de bicicletas rentadas, manteniendo constante la variable hour. Sin embargo al tener en cuenta que las categorías (1, 2, 3 y 4) correspondientes a las estaciones del año (invierno, primavera, verano y otoño) respectivamente, no varian de manera lineal con el numero de bicicletas alquiladas. Por lo tanto no puede afirmarse que cuando pasamos de una estación a otra, las bicicletas alquiladas aumentan en un numero fijo, esto tambien se puede ver en el gráfico de promedios de bicicletas alquiladas por estacion por año. \n",
    "El hecho de la relacion no lineal mencionada, limita la utilidad de un modelo de regresión lineal para este caso y sería mejor indagar con otros modelos que puedan reflejar mejor la complejidad de la relación entre estas variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 4 - Árbol de decisión manual\n",
    "En la celda 4 cree un árbol de decisiones para pronosticar la variable \"total\" iterando **manualmente** sobre las variables \"hour\" y  \"season\". El árbol debe tener al menos 6 nodos finales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 4\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Seleccionamos las variables predictoras (X) y la variable objetivo (y)\n",
    "X = bikes[['hour', 'season']]\n",
    "y = bikes['total']\n",
    "# Definición de parámetros y criterios de parada\n",
    "max_depth = None  # Profundidad máxima del árbol. None significa que los nodos se expanden hasta que todas las hojas sean puras o hasta que contengan menos ejemplos que min_samples_split.\n",
    "num_pct = 10  # Número de puntos de corte a considerar al dividir un nodo.\n",
    "max_features = None  # Número de características a considerar al buscar la mejor división. None significa que se usarán todas las características.\n",
    "min_gain = 0.001  # Ganancia mínima requerida para dividir un nodo.\n",
    "\n",
    "#funcion para calcular el Gini Index\n",
    "def gini(y):\n",
    "    if y.shape[0] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 - (y.mean()**2 + (1 - y.mean())**2)\n",
    "\n",
    "# Definición de la función gini_imputiry para calular la ganancia de una variable predictora j dado el punto de corte k\n",
    "def gini_impurity(X_col, y, split):\n",
    "    filter_l = X_col < split\n",
    "    y_l = y.loc[filter_l]\n",
    "    y_r = y.loc[~filter_l]\n",
    "    \n",
    "    n_l = y_l.shape[0]\n",
    "    n_r = y_r.shape[0]\n",
    "    \n",
    "    gini_y = gini(y)\n",
    "    gini_l = gini(y_l)\n",
    "    gini_r = gini(y_r)\n",
    "    \n",
    "    gini_impurity_ = gini_y - (n_l / (n_l + n_r) * gini_l + n_r / (n_l + n_r) * gini_r)\n",
    "    \n",
    "    return gini_impurity_\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def best_split(X, y, num_pct=10):\n",
    "    features = range(X.shape[1])\n",
    "    best_split = [0, 0, 0]  # j, split, gain\n",
    "\n",
    "    # Para todas las variables\n",
    "    for j in features:\n",
    "        splits = np.percentile(X.iloc[:, j], np.arange(0, 100, 100.0 / (num_pct+1)).tolist())\n",
    "        splits = np.unique(splits)[1:]\n",
    "\n",
    "        # Para cada partición\n",
    "        for split in splits:\n",
    "            gain = gini_impurity(X.iloc[:, j], y, split)\n",
    "            \n",
    "            if gain > best_split[2]:\n",
    "                best_split = [j, split, gain]\n",
    "    \n",
    "    return best_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención de la variable 'j', su punto de corte 'split' y su ganancia 'gain'\n",
    "j, split, gain = best_split(X, y, 5)\n",
    "j, split, gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División de las observaciones usando la mejor variable 'j' y su punto de corte 'split'\n",
    "filter_l = X.iloc[:, j] < split\n",
    "\n",
    "y_l = y.loc[filter_l]\n",
    "y_r = y.loc[~filter_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape[0], y_l.shape[0], y_r.shape[0]\n",
    "y.mean(), y_l.mean(), y_r.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_grow(X, y, level=0, min_gain=0.001, max_depth=None, min_leaf_nodes=6, num_pct=10):\n",
    "    \n",
    "    # Si solo es una observación\n",
    "    if X.shape[0] == 1:\n",
    "        tree = dict(y_pred=y.iloc[:1].values[0], y_prob=0.5, level=level, split=-1, n_samples=1, gain=0)\n",
    "        return tree\n",
    "    \n",
    "    # Calcular la mejor división\n",
    "    j, split, gain = best_split(X, y, num_pct)\n",
    "    \n",
    "    # Guardar el árbol y estimar la predicción\n",
    "    y_pred = int(y.mean() >= 0.5) \n",
    "    y_prob = (y.sum() + 1.0) / (y.shape[0] + 2.0)  # Corrección Laplace \n",
    "    \n",
    "    tree = dict(y_pred=y_pred, y_prob=y_prob, level=level, split=-1, n_samples=X.shape[0], gain=gain)\n",
    "    # Revisar el criterio de parada \n",
    "    if gain < min_gain or X.shape[0] < min_leaf_nodes:\n",
    "        return tree\n",
    "    if max_depth is not None:\n",
    "        if level >= max_depth:\n",
    "            return tree   \n",
    "    \n",
    "    # Continuar creando la partición\n",
    "    filter_l = X.iloc[:, j] < split\n",
    "    X_l, y_l = X.loc[filter_l], y.loc[filter_l]\n",
    "    X_r, y_r = X.loc[~filter_l], y.loc[~filter_l]\n",
    "    tree['split'] = [j, split]\n",
    "\n",
    "    # Siguiente iteración para cada partición\n",
    "    \n",
    "    tree['sl'] = tree_grow(X_l, y_l, level + 1, min_gain=min_gain, max_depth=max_depth, min_leaf_nodes=min_leaf_nodes, num_pct=num_pct)\n",
    "    tree['sr'] = tree_grow(X_r, y_r, level + 1, min_gain=min_gain, max_depth=max_depth, min_leaf_nodes=min_leaf_nodes, num_pct=num_pct)\n",
    "    \n",
    "    return tree\n",
    "\n",
    "# Aplicación de la función tree_grow\n",
    "tree_grow(X, y, level=0, min_gain=0.001, max_depth=3, num_pct=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 5 - Árbol de decisión con librería\n",
    "En la celda 5 entrene un árbol de decisiones con la **librería sklearn**, usando las variables predictoras \"season\" y \"hour\" y calibre los parámetros que considere conveniente para obtener un mejor desempeño. Recuerde dividir los datos en conjuntos de entrenamiento y validación para esto. Comente el desempeño del modelo con alguna métrica de desempeño de modelos de regresión y compare desempeño con el modelo del punto 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 5\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(bikes[['season', 'hour']], bikes['total'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Instanciar el modelo de árbol de decisiones\n",
    "tree_reg = DecisionTreeRegressor(max_depth=3, min_samples_leaf=5, random_state=42)\n",
    "\n",
    "# Ajustar el modelo a los datos de entrenamiento\n",
    "tree_reg.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones en los datos de validación\n",
    "predictions = tree_reg.predict(X_val)\n",
    "\n",
    "# Evaluar el desempeño del modelo utilizando MSE\n",
    "mse = mean_squared_error(y_val, predictions)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "import numpy as np\n",
    "\n",
    "# Calcular el MAE\n",
    "mae = np.mean(np.abs(y_val - predictions))\n",
    "print(\"MAE:\", mae)\n",
    "\n",
    "# otra métrica de regresión es el coeficiente de determinación (R^2)\n",
    "r2 = tree_reg.score(X_val, y_val)\n",
    "print(\"R^2 Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respecto al modelo del punto 3, presenta un MSE menor, también el MAE es aproximadamente la mitad del estimado y el coeficiente de determinación (R^2) también presenta una notable mejora, aumentando al doble. estos valores indican que el modelo del punto 5 presenta un mejor desempeño que el del punto 3. el valor del coeficiente de determinación indica que el modelo explica el 45.8% de la varianza en el promedio total de bicicletas rentadas y el MAE indica que en promedio las predicciones difieren de los datos reales en aproximadamente 92 bicicletas.\n",
    "\n",
    "Valores obtenidos en punto 3\n",
    "R^2 Score: 0.18805882759715697\n",
    "Mean Squared Error: 26640.03254457677\n",
    "MAE: 191.57413191254824"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte B - Métodos de ensamblajes\n",
    "En esta parte del taller se usará el conjunto de datos de Popularidad de Noticias Online. El objetivo es predecir si la notica es popular o no, la popularidad está dada por la cantidad de reacciones en redes sociales. Para más detalles puede visitar el siguiente enlace: [datos](https://archive.ics.uci.edu/ml/datasets/online+news+popularity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos popularidad de noticias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de la información de archivo .csv\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/davidzarruk/MIAD_ML_NLP_2023/main/datasets/mashable.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición variable de interes y variables predictoras\n",
    "X = df.drop(['url', 'Popular'], axis=1)\n",
    "y = df['Popular']\n",
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División de la muestra en set de entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 6 - Árbol de decisión y regresión logística\n",
    "En la celda 6 construya un árbol de decisión y una regresión logística. Para el árbol calibre al menos un parámetro y evalúe el desempeño de cada modelo usando las métricas de Accuracy y F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 6\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instanciar y entrenar el modelo de árbol de decisión\n",
    "tree_model = DecisionTreeClassifier(max_depth=5)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones con el modelo de árbol de decisión\n",
    "tree_predictions = tree_model.predict(X_test)\n",
    "\n",
    "# Calcular la precisión y el F1-score del árbol de decisión\n",
    "tree_accuracy = accuracy_score(y_test, tree_predictions)\n",
    "tree_f1 = f1_score(y_test, tree_predictions)\n",
    "\n",
    "# Instanciar y entrenar el modelo de regresión logística\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones con el modelo de regresión logística\n",
    "logistic_predictions = logistic_model.predict(X_test)\n",
    "\n",
    "# Calcular la precisión y el F1-score de la regresión logística\n",
    "logistic_accuracy = accuracy_score(y_test, logistic_predictions)\n",
    "logistic_f1 = f1_score(y_test, logistic_predictions)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Resultados del árbol de decisión:\")\n",
    "print(\"Accuracy:\", tree_accuracy)\n",
    "print(\"F1-score:\", tree_f1)\n",
    "print(\"\\nResultados de la regresión logística:\")\n",
    "print(\"Accuracy:\", logistic_accuracy)\n",
    "print(\"F1-score:\", logistic_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se encontraron resultados semejantes para los dos metodos teniendo en cuenta que el parámetro escogido en el caso del arbol fue max_depth=5 (profundidad máxima del árbol). En detalle se puede decir que el árbol tiene un mejor accuracy, es decir predice ligeramente mejor las noticias que realmente son populares de acuerdo a las reacciones en redes sociales, respecto al F1-score la diferencia tampoco es muy notable, sin embargo estan mejor los resultados del arbol de decisión en cuanto a su equilibrio entre precisión y sensibilidad. Cabe resaltar que el F1_score ayuda a entender el rendimiento del modelo incluso si las clases estuvieran desbalanceadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 7 - Votación Mayoritaria\n",
    "En la celda 7 elabore un esamble con la metodología de **Votación mayoritaria** compuesto por 300 muestras bagged donde:\n",
    "\n",
    "-las primeras 100 muestras vienen de árboles de decisión donde max_depth tome un valor de su elección\\\n",
    "-las segundas 100 muestras vienen de árboles de decisión donde min_samples_leaf tome un valor de su elección\\\n",
    "-las últimas 100 muestras vienen de regresiones logísticas\n",
    "\n",
    "Evalúe cada uno de los tres modelos de manera independiente utilizando las métricas de Accuracy y F1-Score, luego evalúe el ensamble de modelos y compare los resultados. \n",
    "\n",
    "Nota: \n",
    "\n",
    "Para este ensamble de 300 modelos, deben hacer votación mayoritaria. Esto lo pueden hacer de distintas maneras. La más \"fácil\" es haciendo la votación \"manualmente\", como se hace a partir del minuto 5:45 del video de Ejemplo práctico de emsablajes en Coursera. Digo que es la más fácil porque si hacen la votación mayoritaria sobre las 300 predicciones van a obtener lo que se espera.\n",
    "\n",
    "Otra opción es: para cada uno de los 3 tipos de modelos, entrenar un ensamble de 100 modelos cada uno. Predecir para cada uno de esos tres ensambles y luego predecir como un ensamble de los 3 ensambles. La cuestión es que la votación mayoritaria al usar los 3 ensambles no necesariamente va a generar el mismo resultado que si hacen la votación mayoritaria directamente sobre los 300 modelos. Entonces, para los que quieran hacer esto, deben hacer ese último cálculo con cuidado.\n",
    "\n",
    "Para los que quieran hacerlo como ensamble de ensambles, digo que se debe hacer el ensamble final con cuidado por lo siguiente. Supongamos que:\n",
    "\n",
    "* para los 100 árboles del primer tipo, la votación mayoritaria es: 55% de los modelos predicen que la clase de una observación es \"1\"\n",
    "* para los 100 árboles del segundo tipo, la votación mayoritaria es: 55% de los modelos predicen que la clase de una observación es \"1\"\n",
    "* para las 100 regresiones logísticas, la votación mayoritaria es: 10% de los modelos predicen que la clase de una observación es \"1\"\n",
    "\n",
    "Si se hace la votación mayoritaria de los 300 modelos, la predicción de esa observación debería ser: (100*55%+100*55%+100*10%)/300 = 40% de los modelos votan porque la predicción debería ser \"1\". Es decir, la predicción del ensamble es \"0\" (dado que menos del 50% de modelos predijo un 1).\n",
    "\n",
    "Sin embargo, si miramos cada ensamble por separado, el primer ensamble predice \"1\", el segundo ensamble predice \"1\" y el último ensamble predice \"0\". Si hago votación mayoritaria sobre esto, la predicción va a ser \"1\", lo cual es distinto a si se hace la votación mayoritaria sobre los 300 modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 7\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear modelos de árboles de decisión con max_depth=5\n",
    "decision_trees_max_depth = [\n",
    "    ('decision_tree_max_depth_' + str(i), DecisionTreeClassifier(max_depth=5)) for i in range(100)\n",
    "]\n",
    "\n",
    "# Crear modelos de árboles de decisión con min_samples_leaf=5\n",
    "decision_trees_min_samples_leaf = [\n",
    "    ('decision_tree_min_samples_leaf_' + str(i), DecisionTreeClassifier(min_samples_leaf=5)) for i in range(100)\n",
    "]\n",
    "\n",
    "# Crear modelos de regresión logística\n",
    "logistic_reg_models = [\n",
    "    ('logistic_regression_' + str(i), LogisticRegression(max_iter=1000)) for i in range(100)\n",
    "]\n",
    "\n",
    "# Unir todos los modelos en una sola lista\n",
    "all_models = decision_trees_max_depth + decision_trees_min_samples_leaf + logistic_reg_models\n",
    "\n",
    "# Crear el ensamble utilizando la metodología de votación mayoritaria\n",
    "ensemble = VotingClassifier(estimators=all_models, voting='hard')\n",
    "\n",
    "# Entrenar el ensamble\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el ensamble\n",
    "y_pred_ensemble = ensemble.predict(X_test)\n",
    "accuracy_ensemble = accuracy_score(y_test, y_pred_ensemble)\n",
    "f1_ensemble = f1_score(y_test, y_pred_ensemble)\n",
    "print(\"\\nResultados del ensamble:\")\n",
    "print(f\"Accuracy = {accuracy_ensemble:.4f}, F1-Score = {f1_ensemble:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación de cada modelo individualmente\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model_name, model_instance = model\n",
    "    model_instance.fit(X_train, y_train)\n",
    "    y_pred = model_instance.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"Modelo {model_name}: Accuracy = {accuracy:.4f}, F1-Score = {f1:.4f}\")\n",
    "\n",
    "# Calcular y mostrar las métricas para cada modelo\n",
    "for model in all_models:\n",
    "    evaluate_model(model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados indican que el ensamblaje genera un rendimiento ligeramente mejor o similar a los que presentan los diferentes modelos evaluados por medio de la exactitud y el F1-score.Sin embargo en cuanto al F1-Score los resultados son algo inferiores a los obtenidos con un arbol de decision variando la profundidad máxima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 8 - Votación Ponderada\n",
    "En la celda 8 elabore un ensamble con la metodología de **Votación ponderada** compuesto por 300 muestras bagged para los mismos tres escenarios del punto 7. Evalúe los modelos utilizando las métricas de Accuracy y F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 8\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Unir todos los modelos en una sola lista\n",
    "all_models = decision_trees_max_depth + decision_trees_min_samples_leaf + logistic_reg_models\n",
    "\n",
    "# Crear el clasificador de votación ponderada\n",
    "voting_clf = VotingClassifier(estimators=all_models, voting='soft')\n",
    "\n",
    "# Crear el clasificador bagged para el ensamble\n",
    "bagging_clf = BaggingClassifier(base_estimator=voting_clf, n_estimators=300, random_state=42)\n",
    "\n",
    "# Entrenar el modelo de ensamble\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predecir con el modelo de ensamble en el conjunto de prueba\n",
    "y_pred = bagging_clf.predict(X_test)\n",
    "\n",
    "# Calcular métricas de evaluación\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"Accuracy del modelo de ensamble:\", accuracy)\n",
    "print(\"F1-Score del modelo de ensamble:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 9 - Comparación y análisis de resultados\n",
    "En la celda 9 comente sobre los resultados obtenidos con las metodologías usadas en los puntos 7 y 8, compare los resultados y enuncie posibles ventajas o desventajas de cada una de ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
